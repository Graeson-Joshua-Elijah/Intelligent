{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9076ee-bde5-42e8-9d9b-3bb5fd64504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7de14e-319e-4dc9-b0db-6d6a252d2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee63ca62-e803-4451-ae58-f361df75221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cc0b280-dc45-45b7-916c-9ea793235b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=1, circle_radius=2), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=1, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91c9d280-6420-4493-a31e-61a6b8f43ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2080b06-757b-4467-aa07-3ccd2f9d1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('llp') \n",
    "# Actions that we try to detect\n",
    "actions = np.array(['Are you a student','Are you hungry','Awesome','Best of luck','Call','Come','Do you understand','Hello','No','Please','Victory'])\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 20\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n",
    "# Folder start\n",
    "start_folder = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5d57737-fc22-4c7e-a4ed-f2ef1b60a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions: \n",
    "    for sequence in range(0,no_sequences):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0df0a899-b1ab-4aea-9090-6da2b559d624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "6/6 [==============================] - 2s 166ms/step - loss: 2.3183 - categorical_accuracy: 0.1705\n",
      "Epoch 2/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 2.0247 - categorical_accuracy: 0.2955\n",
      "Epoch 3/150\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 1.7512 - categorical_accuracy: 0.3523\n",
      "Epoch 4/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 1.5406 - categorical_accuracy: 0.3864\n",
      "Epoch 5/150\n",
      "6/6 [==============================] - 1s 147ms/step - loss: 1.4169 - categorical_accuracy: 0.4205\n",
      "Epoch 6/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 1.2677 - categorical_accuracy: 0.5000\n",
      "Epoch 7/150\n",
      "6/6 [==============================] - 1s 140ms/step - loss: 1.1309 - categorical_accuracy: 0.5739\n",
      "Epoch 8/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.9694 - categorical_accuracy: 0.6307\n",
      "Epoch 9/150\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 0.8736 - categorical_accuracy: 0.6648\n",
      "Epoch 10/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.8161 - categorical_accuracy: 0.7273\n",
      "Epoch 11/150\n",
      "6/6 [==============================] - 1s 140ms/step - loss: 0.7037 - categorical_accuracy: 0.7386\n",
      "Epoch 12/150\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.6131 - categorical_accuracy: 0.8466\n",
      "Epoch 13/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.5641 - categorical_accuracy: 0.8239\n",
      "Epoch 14/150\n",
      "6/6 [==============================] - 1s 150ms/step - loss: 0.5408 - categorical_accuracy: 0.8068\n",
      "Epoch 15/150\n",
      "6/6 [==============================] - 1s 142ms/step - loss: 0.4400 - categorical_accuracy: 0.8864\n",
      "Epoch 16/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.4019 - categorical_accuracy: 0.9034\n",
      "Epoch 17/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.3703 - categorical_accuracy: 0.9034\n",
      "Epoch 18/150\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 0.3755 - categorical_accuracy: 0.8920\n",
      "Epoch 19/150\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.2870 - categorical_accuracy: 0.9489\n",
      "Epoch 20/150\n",
      "6/6 [==============================] - 1s 133ms/step - loss: 0.2920 - categorical_accuracy: 0.9489\n",
      "Epoch 21/150\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 0.2503 - categorical_accuracy: 0.9432\n",
      "Epoch 22/150\n",
      "6/6 [==============================] - 1s 141ms/step - loss: 0.2684 - categorical_accuracy: 0.9261\n",
      "Epoch 23/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.2712 - categorical_accuracy: 0.9261\n",
      "Epoch 24/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.2453 - categorical_accuracy: 0.9432\n",
      "Epoch 25/150\n",
      "6/6 [==============================] - 1s 144ms/step - loss: 0.1858 - categorical_accuracy: 0.9545\n",
      "Epoch 26/150\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.2085 - categorical_accuracy: 0.9318\n",
      "Epoch 27/150\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 0.2113 - categorical_accuracy: 0.9432\n",
      "Epoch 28/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.1810 - categorical_accuracy: 0.9432\n",
      "Epoch 29/150\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.1797 - categorical_accuracy: 0.9489\n",
      "Epoch 30/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.1400 - categorical_accuracy: 0.9716\n",
      "Epoch 31/150\n",
      "6/6 [==============================] - 1s 146ms/step - loss: 0.1309 - categorical_accuracy: 0.9716\n",
      "Epoch 32/150\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 0.1165 - categorical_accuracy: 0.9659\n",
      "Epoch 33/150\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.1062 - categorical_accuracy: 0.9716\n",
      "Epoch 34/150\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 0.1037 - categorical_accuracy: 0.9773\n",
      "Epoch 35/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.0991 - categorical_accuracy: 0.9602\n",
      "Epoch 36/150\n",
      "6/6 [==============================] - 1s 162ms/step - loss: 0.1097 - categorical_accuracy: 0.9716\n",
      "Epoch 37/150\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.0866 - categorical_accuracy: 0.9830\n",
      "Epoch 38/150\n",
      "6/6 [==============================] - 1s 148ms/step - loss: 0.0971 - categorical_accuracy: 0.9773\n",
      "Epoch 39/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0781 - categorical_accuracy: 0.9886\n",
      "Epoch 40/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0807 - categorical_accuracy: 0.9659\n",
      "Epoch 41/150\n",
      "6/6 [==============================] - 1s 144ms/step - loss: 0.0686 - categorical_accuracy: 0.9886\n",
      "Epoch 42/150\n",
      "6/6 [==============================] - 1s 140ms/step - loss: 0.0538 - categorical_accuracy: 0.9943\n",
      "Epoch 43/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0507 - categorical_accuracy: 0.9943\n",
      "Epoch 44/150\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.0435 - categorical_accuracy: 0.9943\n",
      "Epoch 45/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0450 - categorical_accuracy: 0.9943\n",
      "Epoch 46/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0452 - categorical_accuracy: 0.9886\n",
      "Epoch 47/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0423 - categorical_accuracy: 0.9943\n",
      "Epoch 48/150\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.0342 - categorical_accuracy: 0.9943\n",
      "Epoch 49/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0319 - categorical_accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0296 - categorical_accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0256 - categorical_accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "6/6 [==============================] - 1s 140ms/step - loss: 0.0239 - categorical_accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.0291 - categorical_accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0567 - categorical_accuracy: 0.9773\n",
      "Epoch 55/150\n",
      "6/6 [==============================] - 1s 138ms/step - loss: 0.0558 - categorical_accuracy: 0.9943\n",
      "Epoch 56/150\n",
      "6/6 [==============================] - 1s 148ms/step - loss: 0.0539 - categorical_accuracy: 0.9830\n",
      "Epoch 57/150\n",
      "6/6 [==============================] - 1s 142ms/step - loss: 0.0648 - categorical_accuracy: 0.9773\n",
      "Epoch 58/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0514 - categorical_accuracy: 0.9943\n",
      "Epoch 59/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0404 - categorical_accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0331 - categorical_accuracy: 0.9943\n",
      "Epoch 61/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0291 - categorical_accuracy: 0.9943\n",
      "Epoch 62/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.0247 - categorical_accuracy: 0.9943\n",
      "Epoch 63/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0192 - categorical_accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "6/6 [==============================] - 1s 138ms/step - loss: 0.0161 - categorical_accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.0188 - categorical_accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "6/6 [==============================] - 1s 145ms/step - loss: 0.0275 - categorical_accuracy: 0.9943\n",
      "Epoch 67/150\n",
      "6/6 [==============================] - 1s 138ms/step - loss: 0.0214 - categorical_accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "6/6 [==============================] - 1s 148ms/step - loss: 0.0143 - categorical_accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0127 - categorical_accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0098 - categorical_accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0095 - categorical_accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "6/6 [==============================] - 1s 143ms/step - loss: 0.0091 - categorical_accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "6/6 [==============================] - 1s 138ms/step - loss: 0.0069 - categorical_accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.0078 - categorical_accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "6/6 [==============================] - 1s 141ms/step - loss: 0.0054 - categorical_accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0059 - categorical_accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "6/6 [==============================] - 1s 138ms/step - loss: 0.0052 - categorical_accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "6/6 [==============================] - 1s 142ms/step - loss: 0.0048 - categorical_accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "6/6 [==============================] - 1s 142ms/step - loss: 0.0052 - categorical_accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.0046 - categorical_accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.0044 - categorical_accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "6/6 [==============================] - 1s 138ms/step - loss: 0.0041 - categorical_accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 0.0040 - categorical_accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "6/6 [==============================] - 1s 148ms/step - loss: 0.0039 - categorical_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "6/6 [==============================] - 1s 138ms/step - loss: 0.0038 - categorical_accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "6/6 [==============================] - 1s 148ms/step - loss: 0.0037 - categorical_accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0035 - categorical_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "6/6 [==============================] - 1s 142ms/step - loss: 0.0034 - categorical_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0033 - categorical_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "6/6 [==============================] - 1s 147ms/step - loss: 0.0032 - categorical_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.0031 - categorical_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "6/6 [==============================] - 1s 140ms/step - loss: 0.0031 - categorical_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0029 - categorical_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0028 - categorical_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0028 - categorical_accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "6/6 [==============================] - 1s 138ms/step - loss: 0.0026 - categorical_accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.0026 - categorical_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0025 - categorical_accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0024 - categorical_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "6/6 [==============================] - 1s 144ms/step - loss: 0.0026 - categorical_accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.0026 - categorical_accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.0027 - categorical_accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0023 - categorical_accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0023 - categorical_accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.0021 - categorical_accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "6/6 [==============================] - 1s 165ms/step - loss: 0.0021 - categorical_accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "6/6 [==============================] - 1s 157ms/step - loss: 0.0021 - categorical_accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "6/6 [==============================] - 1s 140ms/step - loss: 0.0019 - categorical_accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "6/6 [==============================] - 1s 142ms/step - loss: 0.0018 - categorical_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "6/6 [==============================] - 1s 145ms/step - loss: 0.0018 - categorical_accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.0018 - categorical_accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "6/6 [==============================] - 1s 140ms/step - loss: 0.0018 - categorical_accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0018 - categorical_accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0017 - categorical_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.0015 - categorical_accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "6/6 [==============================] - 1s 151ms/step - loss: 0.0016 - categorical_accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "6/6 [==============================] - 1s 167ms/step - loss: 0.0015 - categorical_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "6/6 [==============================] - 1s 164ms/step - loss: 0.0015 - categorical_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "6/6 [==============================] - 1s 141ms/step - loss: 0.0015 - categorical_accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0015 - categorical_accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 0.0014 - categorical_accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "6/6 [==============================] - 1s 144ms/step - loss: 0.0013 - categorical_accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "6/6 [==============================] - 1s 143ms/step - loss: 0.0013 - categorical_accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.0012 - categorical_accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.0012 - categorical_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "6/6 [==============================] - 1s 138ms/step - loss: 0.0012 - categorical_accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "6/6 [==============================] - 1s 145ms/step - loss: 0.0012 - categorical_accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "6/6 [==============================] - 1s 146ms/step - loss: 0.0011 - categorical_accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0011 - categorical_accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "6/6 [==============================] - 1s 143ms/step - loss: 0.0012 - categorical_accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0011 - categorical_accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0011 - categorical_accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "6/6 [==============================] - 1s 138ms/step - loss: 0.0010 - categorical_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 9.9520e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "6/6 [==============================] - 1s 142ms/step - loss: 9.6731e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 9.3704e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 9.3823e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 8.9941e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "6/6 [==============================] - 1s 147ms/step - loss: 8.9354e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "6/6 [==============================] - 1s 144ms/step - loss: 8.8393e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "6/6 [==============================] - 1s 145ms/step - loss: 8.5414e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "6/6 [==============================] - 1s 145ms/step - loss: 8.9608e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 8.0303e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "6/6 [==============================] - 1s 140ms/step - loss: 8.5642e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 8.0384e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 146/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 137ms/step - loss: 8.0452e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "6/6 [==============================] - 1s 142ms/step - loss: 7.7062e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "6/6 [==============================] - 1s 138ms/step - loss: 7.8073e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "6/6 [==============================] - 1s 149ms/step - loss: 7.3434e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 7.2487e-04 - categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x294b06da0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "tb_callback = TensorBoard(log_dir='./logs', histogram_freq=1)\n",
    "\n",
    "actions = np.array(['Are you a student', 'Are you hungry', 'Awesome', 'Best of luck', 'Call', 'Come', 'Do you understand', 'Hello', 'No', 'Please', 'Victory'])\n",
    "label_map = {label: num for num, label in enumerate(actions)}\n",
    "DATA_PATH = os.path.join('llp')\n",
    "sequence_length = 30\n",
    "sequences, labels = [], []\n",
    "\n",
    "for action in actions:\n",
    "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "# Reshape the input data for 3D CNN\n",
    "input_shape = (sequence_length, 126, 1, 1)  # Adjust input shape\n",
    "X_train = X_train.reshape(-1, *input_shape)\n",
    "X_test = X_test.reshape(-1, *input_shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 1), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 1)))\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 1), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, callbacks=[tb_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eeff9539-35ee-4ee1-8ba9-c7203d107fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 28, 124, 1, 32)    320       \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3  (None, 14, 62, 1, 32)     0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 12, 60, 1, 64)     18496     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPoolin  (None, 6, 30, 1, 64)      0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 11520)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                737344    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 758603 (2.89 MB)\n",
      "Trainable params: 758603 (2.89 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "406ddea1-8292-401c-b3f8-c30f904ff09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edb04adf-7512-41aa-ad80-b782444d136e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "456c070b-6260-4e1c-9991-8e968729244c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5aff496d-03b0-4ed1-a332-d19484bfbec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('3dcnntrail_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95e51e04-85e0-4d92-afda-8e93b41cf56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Load the saved model\n",
    "model = load_model('3dcnntrail_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d78e146a-a913-4141-8b48-8127ab528325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[39,  0],\n",
       "        [ 0,  5]],\n",
       "\n",
       "       [[42,  1],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[40,  0],\n",
       "        [ 0,  4]],\n",
       "\n",
       "       [[35,  3],\n",
       "        [ 0,  6]],\n",
       "\n",
       "       [[39,  0],\n",
       "        [ 3,  2]],\n",
       "\n",
       "       [[39,  0],\n",
       "        [ 0,  5]],\n",
       "\n",
       "       [[39,  0],\n",
       "        [ 0,  5]],\n",
       "\n",
       "       [[40,  0],\n",
       "        [ 0,  4]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  2]],\n",
       "\n",
       "       [[39,  0],\n",
       "        [ 1,  4]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  2]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38845daa-b61f-4999-ade0-fd0263c1760e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maccuracy_score\u001b[49m(ytrue, yhat)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "072f28e2-44f7-49c7-bcdf-74b38f53d88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in /Applications/miniconda3/lib/python3.10/site-packages (2.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baffe7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans==4.0.0-rc1 in /Applications/miniconda3/lib/python3.10/site-packages (4.0.0rc1)\n",
      "Requirement already satisfied: httpx==0.13.3 in /Applications/miniconda3/lib/python3.10/site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: hstspreload in /Applications/miniconda3/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.1)\n",
      "Requirement already satisfied: sniffio in /Applications/miniconda3/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.2.0)\n",
      "Requirement already satisfied: chardet==3.* in /Applications/miniconda3/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in /Applications/miniconda3/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /Applications/miniconda3/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in /Applications/miniconda3/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: certifi in /Applications/miniconda3/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.12.7)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /Applications/miniconda3/lib/python3.10/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in /Applications/miniconda3/lib/python3.10/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /Applications/miniconda3/lib/python3.10/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /Applications/miniconda3/lib/python3.10/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "397b156b-8671-4b9c-aefa-3f27a1abd622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'draw_styled_landmarks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m image, results \u001b[38;5;241m=\u001b[39m mediapipe_detection(frame, holistic)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Draw landmarks\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mdraw_styled_landmarks\u001b[49m(image, results)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Prediction logic\u001b[39;00m\n\u001b[1;32m     41\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m extract_keypoints(results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'draw_styled_landmarks' is not defined"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "import pygame\n",
    "from googletrans import Translator\n",
    "\n",
    "def translate_text(text, src_lang, dest_lang):\n",
    "    translator = Translator()\n",
    "    \n",
    "    # Translate text from source language to destination language\n",
    "    translation1 = translator.translate(text, src=src_lang, dest=dest_lang)\n",
    "    \n",
    "    # Translate back from destination language to source language\n",
    "    translation2 = translator.translate(translation1.text, src=dest_lang, dest=src_lang)\n",
    "    \n",
    "    return translation1.text, translation2.text\n",
    "\n",
    "\n",
    "# Code for real-time prediction using MediaPipe\n",
    "cap = cv2.VideoCapture(1)\n",
    "sequence_length = 30\n",
    "input_shape = (sequence_length, 126, 1, 1) \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.7, min_tracking_confidence=0.8) as holistic:\n",
    "    sequence = []\n",
    "    sentence = []\n",
    "    predictions = []\n",
    "    threshold = 0.94\n",
    "    vote_window_size = 10\n",
    "    vote_window = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections using MediaPipe\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        # Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "\n",
    "        if len(sequence) == 30:\n",
    "            # Reshape the sequence for prediction\n",
    "            sequence_for_prediction = np.expand_dims(sequence, axis=0)\n",
    "            sequence_for_prediction = sequence_for_prediction.reshape(-1, *input_shape)\n",
    "            res = model.predict(sequence_for_prediction)[0]\n",
    "            action = actions[np.argmax(res)]\n",
    "\n",
    "            # Add the action to the vote window\n",
    "            vote_window.append(action)\n",
    "\n",
    "            # Perform action recognition based on the majority vote\n",
    "            if len(vote_window) >= vote_window_size:\n",
    "                recognized_action = max(set(vote_window), key=vote_window.count)\n",
    "                print(recognized_action)\n",
    "                predictions.append(recognized_action)\n",
    "                vote_window = []\n",
    "\n",
    "                # Visualization logic\n",
    "                if recognized_action == \"_\":\n",
    "                    predictions.append(\"\")\n",
    "                else:\n",
    "                    predictions.append(recognized_action)\n",
    "\n",
    "                if np.unique(predictions[-10:])[0] == recognized_action:\n",
    "                    if res[np.argmax(res)] > threshold:\n",
    "                        if len(sentence) > 0:\n",
    "                            if recognized_action != sentence[-1]:\n",
    "                                sentence.append(recognized_action)\n",
    "                                language = 'en'\n",
    "                                myobj = gTTS(text=recognized_action, lang = language, slow = False)\n",
    "                                translated_text1.save('welcome.mp3')\n",
    "                                sound = pygame.mixer.Sound('welcome.mp3')\n",
    "                                #Google Gemini concept\n",
    "                                text = myobj\n",
    "                                src_lang = 'en'\n",
    "                                dest_lang = input(\"Enter destination language (e.g., 'fr' for French): \")\n",
    "\n",
    "                                # Translate text bidirectionally\n",
    "                                translated_text1, translated_text2 = translate_text(text, src_lang, dest_lang)\n",
    "\n",
    "                                translated_text1.save('welcome_t.mp3')\n",
    "                                sound = pygame.mixer.Sound('welcome_t.mp3')\n",
    "                                sound.play()\n",
    "                        else:\n",
    "                            sentence.append(recognized_action)\n",
    "\n",
    "                if len(sentence) > 3:\n",
    "                    sentence = sentence[-3:]\n",
    "        \n",
    "        # Display sentence on the screen\n",
    "        cv2.rectangle(image, (0, 0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show the video feed with annotations\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        pygame.init()\n",
    "        # def listToString(s): \n",
    "        #     # initialize an empty string\n",
    "        #     str1 = \"\"         \n",
    "        #     # traverse in the string\n",
    "        #     for ele in sentence[-1:]:\n",
    "        #         str1 += ele         \n",
    "        #     # return string\n",
    "        #     return str1\n",
    "        # anss=listToString(sentence)\n",
    "        # if anss!=\"\":\n",
    "            \n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832a546-9368-4cb9-a59b-4b5e66f7731b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd78fe-1523-42e8-a9bc-25284a3a1c69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
